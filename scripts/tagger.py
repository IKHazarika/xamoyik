# -*- coding: utf-8 -*-"""Assamese Wikipedia time-sensitivity tagger bot (non-LLM, deterministic)."""import argparseimport datetime as dtimport osimport refrom typing import List, Optional, Set, Tupleimport pywikibotimport yamlimport mwparserfromhelldef normalize_for_keyword_search(text: str) -> str:    # very light normalization (no heavy NLP)    return (text or "").lower()def first_matching_keyword(text: str, keywords: List[str]) -> Optional[str]:    t = normalize_for_keyword_search(text)    for kw in keywords:        if not kw:            continue        if kw.lower() in t:            return kw    return Nonedef reason_for_template_as(reason: str, keyword_reason_as: str = "") -> str:    """    Convert the internal (English) trigger reason into a short Assamese label    suitable for template |reason=. Returns "" if unknown (so we omit reason=).    """    if not reason:        return ""    # Assamese-source triggers    if reason.startswith("aswiki category: "):        c = reason.split(": ", 1)[1].strip()        if c:            return c    if reason.startswith("aswiki template: "):        t = reason.split(": ", 1)[1].strip()        if t:            return t    # Wikidata living human rule    if reason == "wikidata living human (Q5, no P570)":        return "জীৱিত ব্যক্তি"    # Wikidata P31 triggers (use broad Assamese labels)    if reason.startswith("wikidata P31: "):        q = reason.split(": ", 1)[1].strip()        q_map = {            "Q6256": "দেশ",            "Q515": "চহৰ/বসতি",            "Q43229": "সংগঠন",            "Q783794": "কোম্পানী",            "Q3918": "বিশ্ববিদ্যালয়",        }        return q_map.get(q, "")    # enwiki template triggers: map common infoboxes to Assamese    if reason.startswith("enwiki template: "):        t = reason.split(": ", 1)[1].strip()        t_map = {            "Infobox officeholder": "জীৱিত পদাধিকাৰী/ৰাজনীতিবিদ",            "Infobox politician": "জীৱিত ৰাজনীতিবিদ",            "Infobox sportsperson": "জীৱিত ক্ৰীড়াবিদ",            "Infobox football biography": "জীৱিত ক্ৰীড়াবিদ",            "Infobox military person": "জীৱিত ব্যক্তি",            "Infobox country": "অস্তিত্বত থকা দেশ",            "Infobox settlement": "অস্তিত্বত থকা চহৰ/বসতি",            "Infobox administrative division": "অস্তিত্বত থকা প্ৰশাসনিক অঞ্চল",            "Infobox political party": "অস্তিত্বত থকা ৰাজনৈতিক দল",            "Infobox election": "নির্বাচন",            "Infobox company": "অস্তিত্বত থকা কোম্পানী",            "Infobox bank": "অস্তিত্বত থকা বেংক",            "Infobox airline": "অস্তিত্বত থকা বিমান সংস্থা",            "Infobox organization": "অস্তিত্বত থকা সংগঠন",            "Infobox university": "অস্তিত্বত থকা বিশ্ববিদ্যালয়",            "Infobox school": "অস্তিত্বত থকা বিদ্যালয়",            "Infobox hospital": "অস্তিত্বত থকা চিকিৎসালয়",            "Infobox government agency": "অস্তিত্বত থকা চৰকাৰী সংস্থা",            "Infobox sports team": "অস্তিত্বত থকা ক্ৰীড়া দল",            "Infobox football club": "অস্তিত্বত থকা ফুটবল ক্লাব",            "Infobox military conflict": "সাময়িক সংঘৰ্ষ",        }        return t_map.get(t, "")    # enwiki category triggers: keep minimal mapping    if reason.startswith("enwiki category: "):        c = reason.split(": ", 1)[1].strip()        if c == "Living people":            return "জীৱিত ব্যক্তি"        if c in {"Ongoing conflicts", "Ongoing military conflicts", "Current wars", "Active insurgencies"}:            return "সাময়িক সংঘৰ্ষ"        return ""    # Prefix-based reasons (rare; keep generic)    if reason.startswith("enwiki category prefix: Elections in "):        return "নির্বাচন"    if reason.startswith("enwiki category prefix: Ongoing "):        return "সাময়িক ঘটনা"    # NEW: keyword reason    if reason.startswith("keyword match"):        # If configured, use user-provided Assamese reason; else fallback.        if keyword_reason_as:            return keyword_reason_as        return "জনসংখ্যা/জিডিপি/মাথাপিছু আয় আদি তথ্য সময়ে সময়ে সলনি হ’ব পাৰে"    return ""def normalize_template_name(name: str) -> str:    return str(name).strip().replace("_", " ").lower()def infobox_has_death_field(wikitext: str, infobox_name: str) -> bool:    """    Return True if the specified infobox template in wikitext has a non-empty    death-related field (meaning the subject is deceased).    """    death_param_names = {        "death_date",        "death date",        "death_date_and_age",        "death year",        "death_year",        "deathyear",        "died",        "date_of_death",        "date of death",        "death",    }    try:        code = mwparserfromhell.parse(wikitext)    except Exception:        return False  # fail open (do not block tagging due to parser issues)    target = normalize_template_name(infobox_name)    for tpl in code.filter_templates(recursive=True):        tpl_name = normalize_template_name(tpl.name)        if tpl_name != target:            continue        for p in tpl.params:            pname = normalize_template_name(p.name)            if pname in death_param_names:                if str(p.value).strip():                    return True        return False    return Falsedef sanitize_reason(reason: str, maxlen: int = 80) -> str:    """Make a safe, short reason string for wikitext/template parameters."""    if not reason:        return ""    r = reason.replace("\n", " ").replace("\r", " ").strip()    r = r.replace("|", "/").replace("{{", "(").replace("}}", ")")    if len(r) > maxlen:        r = r[: maxlen - 1].rstrip() + "…"    return rdef build_edit_summary(base: str, reason: str, maxlen: int = 240) -> str:    """Append reason to edit summary (keeping it short)."""    base = (base or "Bot edit").strip()    r = sanitize_reason(reason, maxlen=80)    if not r:        return base    s = f"{base} — {r}"    if len(s) > maxlen:        s = s[: maxlen - 1].rstrip() + "…"    return sdef insert_template_at_top(wikitext: str, template_call: str) -> str:    return template_call.strip() + "\n" + wikitext.lstrip()def aswiki_trigger_reason(page: pywikibot.Page, triggers: dict) -> Optional[str]:    cfg = triggers.get("aswiki", {}) or {}    cat_exact = list(cfg.get("category_exact", []) or [])    tmp_exact = list(cfg.get("template_exact", []) or [])    cats = get_page_categories_titles(page)    tmps = get_page_templates_titles(page)    for c in cat_exact:        if c in cats:            return f"aswiki category: {c}"    for t in tmp_exact:        if t in tmps:            return f"aswiki template: {t}"    return Nonedef get_wikidata_p31_qids(item: pywikibot.ItemPage) -> Set[str]:    try:        d = item.get()    except Exception:        return set()    claims = d.get("claims", {})    p31 = claims.get("P31", []) or []    qids: Set[str] = set()    for cl in p31:        try:            target = cl.getTarget()            if hasattr(target, "id"):                qids.add(target.id)        except Exception:            continue    return qidsdef wikidata_trigger_reason(item: pywikibot.ItemPage, triggers: dict) -> Optional[str]:    cfg = triggers.get("wikidata", {}) or {}    p31_triggers = list(cfg.get("p31_qids", []) or [])    living_rule = bool(cfg.get("living_human_rule", True))    p31_qids = get_wikidata_p31_qids(item)    for q in p31_triggers:        if q in p31_qids:            return f"wikidata P31: {q}"    if living_rule and "Q5" in p31_qids:        try:            d = item.get()        except Exception:            return None        claims = d.get("claims", {})        if not (claims.get("P570") or []):            return "wikidata living human (Q5, no P570)"    return Nonedef enwiki_page_from_item(item: pywikibot.ItemPage, en_site: pywikibot.Site) -> Optional[pywikibot.Page]:    try:        d = item.get()    except Exception:        return None    sitelinks = d.get("sitelinks", {}) or {}    if "enwiki" not in sitelinks:        return None    sl = sitelinks["enwiki"]    title = None    if isinstance(sl, dict):        title = sl.get("title")    else:        title = getattr(sl, "title", None)    if not title:        return None    return pywikibot.Page(en_site, title)def enwiki_trigger_reason(en_page: pywikibot.Page, triggers: dict) -> Optional[str]:    cfg = triggers.get("enwiki", {}) or {}    cat_exact = list(cfg.get("category_exact", []) or [])    cat_prefix = list(cfg.get("category_prefix", []) or [])    tmp_exact = list(cfg.get("template_exact", []) or [])    tmp_prefix = list(cfg.get("template_prefix", []) or [])    cats = get_page_categories_titles(en_page)    tmps = get_page_templates_titles(en_page)    for c in cat_exact:        if c in cats:            return f"enwiki category: {c}"    person_infoboxes = {        "Infobox person",        "Infobox officeholder",        "Infobox politician",        "Infobox sportsperson",        "Infobox football biography",        "Infobox military person",    }    for t in tmp_exact:        if t in tmps:            # If it is a person-like infobox, don't tag if infobox has death field filled            if t in person_infoboxes:                try:                    wikitext = en_page.get()                except Exception:                    wikitext = ""                if wikitext and infobox_has_death_field(wikitext, t):                    return None            return f"enwiki template: {t}"    for p in cat_prefix:        for c in cats:            if c.startswith(p):                return f"enwiki category prefix: {p}…"    for p in tmp_prefix:        for t in tmps:            if t.startswith(p):                return f"enwiki template prefix: {p}…"    return Nonedef keyword_trigger_reason(as_text: str, en_text: str, triggers: dict) -> Optional[str]:    kw_cfg = triggers.get("keywords", {}) or {}    as_kws = list((kw_cfg.get("aswiki", []) or []))    en_kws = list((kw_cfg.get("enwiki", []) or []))    hit = first_matching_keyword(as_text, as_kws)    if hit:        return f"keyword match (aswiki): {hit}"    hit2 = first_matching_keyword(en_text, en_kws)    if hit2:        return f"keyword match (enwiki): {hit2}"    return Nonedef should_tag_page(    as_page: pywikibot.Page,    as_text: str,    triggers: dict,    en_site: pywikibot.Site,) -> Tuple[bool, str]:    # 1) Assamese triggers    as_reason = aswiki_trigger_reason(as_page, triggers)    if as_reason:        return True, as_reason    # 2) Wikidata    item = wikidata_item(as_page)    if item is None:        # If no Wikidata, we can still consider keyword triggers on as_text (optional but useful)        kw_reason = keyword_trigger_reason(as_text, "", triggers)        if kw_reason:            return True, kw_reason        return False, "No Wikidata + no Assamese triggers"    wd_reason = wikidata_trigger_reason(item, triggers)    if wd_reason:        return True, wd_reason    # 3) enwiki, if exists    en_page = enwiki_page_from_item(item, en_site)    if en_page is not None:        try:            en_text = en_page.get()        except Exception:            # If enwiki exists but cannot fetch, apply rule: skip (but still allow keyword on as_text only)            kw_reason = keyword_trigger_reason(as_text, "", triggers)            if kw_reason:                return True, kw_reason            return False, "enwiki exists but could not fetch; skip"        en_reason = enwiki_trigger_reason(en_page, triggers)        if en_reason:            return True, en_reason        # Your conservative rule said: if enwiki exists but no triggers, skip.        # BUT you asked to add body keywords as an additional trigger: apply keyword rule here too.        kw_reason = keyword_trigger_reason(as_text, en_text, triggers)        if kw_reason:            return True, kw_reason        return False, "enwiki exists but no triggers matched (skip per rule)"    # 4) No enwiki sitelink: allow keyword triggers on as_text only    kw_reason = keyword_trigger_reason(as_text, "", triggers)    if kw_reason:        return True, kw_reason    return False, "Wikidata exists but no enwiki + no triggers"def load_yaml(path: str) -> dict:    with open(path, "r", encoding="utf-8") as f:        return yaml.safe_load(f)def ymd_from_timestamp(ts: dt.datetime, fmt: str) -> str:    if fmt == "YYYY-MM-DD":        return ts.strftime("%Y-%m-%d")    if fmt == "YYYY-MM":        return ts.strftime("%Y-%m")    if fmt == "YYYY":        return ts.strftime("%Y")    return ts.strftime("%Y-%m-%d")def page_has_template(wikitext: str, template_name: str) -> bool:    tn = re.escape(template_name).replace(r"\ ", r"[ _]")    pattern = r"\{\{\s*" + tn + r"(?=[\s\|}])"    return re.search(pattern, wikitext, flags=re.IGNORECASE) is not Nonedef is_redirect_text(wikitext: str) -> bool:    return bool(re.match(r"^\s*#redirect\b", wikitext, flags=re.IGNORECASE))def get_latest_revision_timestamp(page: pywikibot.Page) -> dt.datetime:    rev = next(page.revisions(total=1))    ts = getattr(rev, "timestamp", None)    if callable(ts):        ts = ts()    if hasattr(ts, "tzinfo") and ts.tzinfo is None:        ts = ts.replace(tzinfo=dt.timezone.utc)    return tsdef fetch_new_pages_titles(    site: pywikibot.Site,    from_days: int,    window_days: int,    limit: int) -> List[str]:    """    Fetch titles of pages created within a time window using logevents (create),    which supports historical ranges (unlike recentchanges retention).    """    now = dt.datetime.now(dt.timezone.utc)    start = now - dt.timedelta(days=from_days)    end = start - dt.timedelta(days=window_days)    titles: List[str] = []    cont = {}    while True:        req = site.simple_request(            action="query",            list="logevents",            letype="create",            leprop="title|timestamp",            lenamespace="0",            lestart=start.strftime("%Y-%m-%dT%H:%M:%SZ"),            leend=end.strftime("%Y-%m-%dT%H:%M:%SZ"),            lelimit=str(min(500, max(1, limit - len(titles)))),            **cont,        )        data = req.submit()        for ev in data.get("query", {}).get("logevents", []):            titles.append(ev["title"])            if len(titles) >= limit:                return titles        if "continue" not in data:            return titles        cont = data["continue"]def get_page_categories_titles(page: pywikibot.Page) -> Set[str]:    return {c.title(with_ns=False) for c in page.categories()}def get_page_templates_titles(page: pywikibot.Page) -> Set[str]:    return {t.title(with_ns=False) for t in page.templates()}def wikidata_item(page: pywikibot.Page) -> Optional[pywikibot.ItemPage]:    try:        return page.data_item()    except Exception:        return Nonedef main():    parser = argparse.ArgumentParser()    parser.add_argument("--days", type=int, default=1)    # Optional window args (window mode)    parser.add_argument("--from-days", type=int, default=0,                        help="Start the window N days back from now (used if --window-days is set)")    parser.add_argument("--window-days", type=int, default=None,                        help="Width of the window in days (enables window mode)")    parser.add_argument("--limit", type=int, default=100)    parser.add_argument("--dry-run", action="store_true")    parser.add_argument("--test-prefix", type=str, default="")    args = parser.parse_args()    root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))    settings = load_yaml(os.path.join(root, "config", "settings.yaml"))    triggers = load_yaml(os.path.join(root, "config", "triggers.yaml"))    keyword_reason_as = (triggers.get("keyword_reason_as") or "").strip()    template_cfg = settings.get("template", {}) or {}    template_name = template_cfg["name"]    date_param = template_cfg["date_param"]    date_fmt = template_cfg["date_format"]    reason_param = template_cfg.get("reason_param", "") or ""    reason_maxlen = int(template_cfg.get("reason_maxlen", 80))    edit_summary_base = settings.get("bot", {}).get("edit_summary", "Tagging time-sensitive article (bot)")    as_site = pywikibot.Site("as", "wikipedia")    as_site.login()    en_site = pywikibot.Site("en", "wikipedia")    # Minimal behavior: if window-days is not provided, interpret --days as "last N days" => from_days=0, window_days=days    if args.window_days is None:        from_days = 0        window_days = int(args.days)    else:        from_days = int(args.from_days)        window_days = int(args.window_days)    titles = fetch_new_pages_titles(        as_site,        from_days,        window_days,        args.limit,    )    print(f"Found {len(titles)} new pages.")    for idx, title in enumerate(titles, start=1):        prefix = f"[{idx}/{len(titles)}]"        if args.test_prefix and not title.startswith(args.test_prefix):            print(f"{prefix} SKIP (test-prefix): {title}")            continue        page = pywikibot.Page(as_site, title)        try:            text = page.get()        except Exception as e:            print(f"{prefix} ERROR (fetch): {title} — {type(e).__name__}")            continue        if is_redirect_text(text):            print(f"{prefix} SKIP (redirect): {title}")            continue        if page_has_template(text, template_name):            print(f"{prefix} SKIP (already tagged): {title}")            continue        decision, reason = should_tag_page(page, text, triggers, en_site)        if not decision:            print(f"{prefix} NO TAG: {title} — {reason}")            continue        ts = get_latest_revision_timestamp(page)        date_str = ymd_from_timestamp(ts, date_fmt)        template_reason_as = reason_for_template_as(reason, keyword_reason_as=keyword_reason_as)        safe_reason_as = sanitize_reason(template_reason_as, maxlen=reason_maxlen)        if reason_param and safe_reason_as:            template_call = f"{{{{{template_name}|{date_param}={date_str}|{reason_param}={safe_reason_as}}}}}"        else:            template_call = f"{{{{{template_name}|{date_param}={date_str}}}}}"        if args.dry_run:            print(f"{prefix} DRY-RUN TAG: {title} — {reason} — {template_call}")            continue        page.text = insert_template_at_top(text, template_call)        summary = build_edit_summary(edit_summary_base, reason)        try:            page.save(summary=summary, minor=False)            print(f"{prefix} TAGGED: {title} — {reason}")        except Exception as e:            print(f"{prefix} ERROR (save): {title} — {type(e).__name__} — {reason}")if __name__ == "__main__":    main()